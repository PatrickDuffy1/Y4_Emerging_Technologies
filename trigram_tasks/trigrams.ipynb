{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641b7122-c742-4429-a56f-d8d5981f1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for reading the book files in Task 1\n",
    "# https://docs.python.org/3/library/os.html\n",
    "import os\n",
    "\n",
    "# Used for cleaning the book text using regex in Task 1\n",
    "# https://docs.python.org/3/library/re.html\n",
    "import re\n",
    "\n",
    "# Used for finding matching sequences in Task 2\n",
    "# https://docs.python.org/3/library/fnmatch.html\n",
    "import fnmatch\n",
    "\n",
    "# Used for choosing a random sequence in Task 2\n",
    "# https://docs.python.org/3/library/random.html\n",
    "import random\n",
    "\n",
    "# Used to write the trigram model to JSON file in Task 4\n",
    "# https://docs.python.org/3/library/json.html\n",
    "import json\n",
    "\n",
    "# Used for rounding numbers in Tasks 1 and 2\n",
    "# https://docs.python.org/3/library/math.html\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093d267-20b3-4c20-ac00-0ce95299c461",
   "metadata": {},
   "source": [
    "### The size of the n-gram model \n",
    "Example: 2 for a bigram model, 3 for a trigram model, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a951a8-304f-46f2-a791-de4b9b593c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GRAM_SIZE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147a4c3-dee8-47e4-9f85-3a8f17fe7e16",
   "metadata": {},
   "source": [
    "## Task 1: Third-order letter approximation model\n",
    "Create a n-gram model from the given books (for third-order letter approximation it will be a trigram model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9be394-3ad6-4ea9-aee2-3486b48ee437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram_model():\n",
    "\n",
    "    # Raise exception if the n-gram size is less than 1\n",
    "    # https://docs.python.org/3/tutorial/errors.html#raising-exceptions\n",
    "    if N_GRAM_SIZE < 1:\n",
    "        raise Exception(\"Error: N-gram size of\", N_GRAM_SIZE, \"is invalid. N-gram size cannot be less than 1.\")\n",
    "\n",
    "    print(\"Creating n-gram character model with sequence size of ...\")\n",
    "\n",
    "    BOOK_DIRECTORY_PATH = \"./books\"\n",
    "\n",
    "    # Read in all of the text from the supplied books as training data\n",
    "    book_text = read_in_files_from_directory(BOOK_DIRECTORY_PATH)\n",
    "\n",
    "    # Remove unwanted characters from the text and convert to uppercase\n",
    "    book_text = clean_text(book_text)\n",
    "\n",
    "    # Create the n_gram model\n",
    "    n_gram_model = create_n_gram_model_from_training_text(book_text)\n",
    "\n",
    "    return n_gram_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e55bdd-0c9c-4322-9e9d-b6b6ea76617b",
   "metadata": {},
   "source": [
    "## Task 2: Third-order letter approximation generation\n",
    "\n",
    "Generate new text using the n-gram model from Task 1 (will be a trigram model for third-order letter approximation generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fdda014-375b-4fad-a6a6-0b078298aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new text based on given initial text until a given character limit is reached\n",
    "def generate_new_text(initial_text, model, num_chars_to_generate):\n",
    "\n",
    "    print(\"Generating new text...\")\n",
    "\n",
    "    has_trailing_whitespace = False\n",
    "\n",
    "    # Check if the initial text has a trailing whitespce\n",
    "    if initial_text[-1] == \" \":\n",
    "        has_trailing_whitespace = True\n",
    "\n",
    "    # Clean the initial text\n",
    "    text = clean_text(initial_text)\n",
    "\n",
    "    # Append a white space to the cleaned text if it had one initially as it has been removed during the cleaning process\n",
    "    if has_trailing_whitespace:\n",
    "        text += \" \"\n",
    "\n",
    "    # If true, print new chacter as it is generated\n",
    "    # If false, only print text once every character has being generated\n",
    "    stream_generation = True\n",
    "\n",
    "    # Raise exception if the length cleaned initial text is less than 2\n",
    "    # https://docs.python.org/3/tutorial/errors.html#raising-exceptions\n",
    "    if len(text) < N_GRAM_SIZE -1:\n",
    "        raise Exception(\"Error: Initial text length for model size\", N_GRAM_SIZE , \"cannot be less than \", (N_GRAM_SIZE - 1))\n",
    "\n",
    "    if stream_generation:\n",
    "        print(text, end=\"\")\n",
    "    \n",
    "    start_index = len(text) - 1\n",
    "\n",
    "    # Generate new characters until the given limit is reached\n",
    "    for char_index in range(start_index, num_chars_to_generate):\n",
    "\n",
    "        # Get the sequence from the end of the text which will be used to generate the next character\n",
    "        sequence = text[char_index - math.floor(N_GRAM_SIZE - 2):char_index + 1]\n",
    "\n",
    "        # Append the generated character to the existing text\n",
    "        text += generate_next_char(sequence, model, stream_generation)\n",
    "\n",
    "    if not stream_generation:\n",
    "        print(text)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146a0bba-e8cd-4c3d-b646-5c80f505be36",
   "metadata": {},
   "source": [
    "## Task 3: Analyze the model\n",
    "\n",
    "Analyze the n-gram model by calculating the percentage of valid words in the generated text from Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70a8b071-5212-4ae0-92e9-5b28db59244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and return the the percentage of valid words in the generated text\n",
    "def calculate_percentage_of_valid_words(word_set, generated_text):\n",
    "\n",
    "    print(\"Evaluating model...\")\n",
    "\n",
    "    # Split the list of words and store them in a list\n",
    "    list_of_words = generated_text.split(\" \")\n",
    "    \n",
    "    total_words = len(list_of_words)\n",
    "    valid_word_count = 0\n",
    "\n",
    "    # Loop through every word in the generated text\n",
    "    for word in list_of_words:\n",
    "\n",
    "        \"\"\" Check if the current word is in the valid word set, and increment valid_word_count if it is.\n",
    "        Note: Valid words are stored as a set because checking if an element is in a set has an average case time\n",
    "        complexity of O(1), while checking if an element is in a list has an average case time complexity of O(n).\n",
    "        https://wiki.python.org/moin/TimeComplexity\n",
    "        \"\"\"\n",
    "        if word in word_set:\n",
    "            valid_word_count += 1\n",
    "\n",
    "    # Return the percentage of valid words\n",
    "    return (valid_word_count / total_words) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdef25b-ddd5-43ab-8aba-e4a73f594f99",
   "metadata": {},
   "source": [
    "## Task 4: Export the model as JSON\n",
    "Export the model as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683c7b8a-d0c8-4073-b202-4312a058c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model as JSON\n",
    "def write_model_to_json_file(model):\n",
    "\n",
    "    print(\"Exporting model as JSON...\")\n",
    "\n",
    "    # The output path is \"trigrams.json\" to meet the requirements.\n",
    "    # Because the program can create different sized n-gram models, a different name like \"n_grams.json\" would be more suitable\n",
    "    file_path = \"trigrams.json\"\n",
    "\n",
    "    # Write the n_gram model to the JSON file\n",
    "    with open(file_path, \"w\") as outfile: \n",
    "        json.dump(model, outfile)\n",
    "\n",
    "    print(\"Model exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b76295-d65e-4278-9aba-a8c587489a7a",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cdff456-7e1e-4927-93b7-d7f2dae55d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a n-gram model based on given training text\n",
    "def create_n_gram_model_from_training_text(text):\n",
    "\n",
    "    n_gram_model = {}\n",
    "    index_offset = math.floor(N_GRAM_SIZE / 2)\n",
    "\n",
    "    # Iterate through all of the characters in the text\n",
    "    for char_index in range(index_offset, len(text) - 1):\n",
    "\n",
    "        # Get the current n character sequence\n",
    "        if N_GRAM_SIZE % 2 == 0:\n",
    "            current_sequence = text[char_index - index_offset:char_index + index_offset]\n",
    "        else:\n",
    "            current_sequence = text[(char_index - index_offset) - 1:char_index + index_offset]\n",
    "\n",
    "        # If sequence exists in dictionary, increase its count by 1.\n",
    "        # Otherwise, add sequence to dictionary and set its count to 1.\n",
    "        if current_sequence in n_gram_model:\n",
    "            n_gram_model[current_sequence] += 1\n",
    "        else:\n",
    "            n_gram_model[current_sequence] = 1\n",
    "            \n",
    "    return n_gram_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7fbad3d-080c-4c1c-b529-b3e90a8bab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files in a given directory\n",
    "def read_in_files_from_directory(directory_name):\n",
    "    \n",
    "    # Get the file names the books\n",
    "    book_list = os.listdir(directory_name)\n",
    "    text = \"\"\n",
    "\n",
    "    print(\"Training data books:\", book_list, \"\\n\")\n",
    "\n",
    "    # Read in all of the text from the books\n",
    "    for book in book_list:\n",
    "        # Open the current book\n",
    "        f = open(directory_name + \"/\" + book, \"r\", encoding=\"utf8\")\n",
    "\n",
    "        # Read the contents of the current book\n",
    "        current_book_text = f.read()\n",
    "\n",
    "        # Remove the preamble and postamble from the current book\n",
    "        current_book_text = remove_preabmle_and_postamble(current_book_text)\n",
    "        \n",
    "        text += current_book_text + \"\\n\"\n",
    "        f.close()\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b13f4f5-bdbf-4d28-bf5f-303e9a350fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove preabmle and postamble from given book text\n",
    "def remove_preabmle_and_postamble(text):\n",
    "\n",
    "    end_of_preamble_string = \"*\\n\"\n",
    "    end_of_postamble_string = \"\\n*\"\n",
    "\n",
    "    # Remove preamble and postabmle\n",
    "    # Modeified from https://stackoverflow.com/a/59903231\n",
    "    text = text[text.find(end_of_preamble_string):text.rfind(end_of_postamble_string)]\n",
    "\n",
    "    # Remove \"*\" from start and end of trimmed text\n",
    "    text = text[1:-1]\n",
    "\n",
    "    # Remove blank lines from start and end of from trimmed text\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6eb382b2-8af6-41f2-9574-666eea5f55b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unwanted characters from a given string\n",
    "def clean_text(text):\n",
    "\n",
    "    # Remove unwanted characters from the text\n",
    "    # https://docs.python.org/3/library/re.html\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z\\s.]', '', text)\n",
    "    #cleaned_text = re.sub(' +', ' ', cleaned_text)\n",
    "\n",
    "    # https://stackoverflow.com/a/1546251\n",
    "    cleaned_text = \" \".join(cleaned_text.split())\n",
    "    \n",
    "    cleaned_text = cleaned_text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Convert all characters to uppercase\n",
    "    cleaned_text = cleaned_text.upper()\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc721cd-ec8e-423e-bf8d-6be737d63a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the next character based on the previous two characters \n",
    "def generate_next_char(sequence, model, stream_generation):\n",
    "\n",
    "    #print(sequence)\n",
    "\n",
    "    # Find all sequences where the first two characters match the given two character sequence\n",
    "    matching_sequences = find_matching_sequences(sequence, model)\n",
    "\n",
    "    # Randomly choose a sequence based on the sequence weights\n",
    "    # https://docs.python.org/3/library/random.html\n",
    "    chosen_sequence = str(random.choices(list(matching_sequences.keys()), weights = list(matching_sequences.values()))[0])\n",
    "\n",
    "    # Get the last character of the chosen sequence\n",
    "    chosen_character = chosen_sequence[-1]\n",
    "    \n",
    "    if stream_generation:\n",
    "        print(chosen_character, end=\"\")\n",
    "\n",
    "    # Return the chosen character\n",
    "    return chosen_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3817230e-9231-4696-ba87-97830825ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all n-gram sequences that have the same first two characters as the given two character sequence\n",
    "def find_matching_sequences(sequence, model):\n",
    "\n",
    "    # Get all of the n-gram sequences\n",
    "    matching_sequences_list = model.keys()\n",
    "\n",
    "    # Get all of the sequences where thefirst two characters match the given two character sequence.\n",
    "    matching_sequences_list = fnmatch.filter(matching_sequences_list, sequence + \"?\")\n",
    "    \n",
    "    matching_sequences_dict = {}\n",
    "\n",
    "    # Create dictionary from the matching sequences and the amount of times they appeared in the training text\n",
    "    for sequence in matching_sequences_list:\n",
    "        matching_sequences_dict[sequence] = model[sequence]\n",
    "    \n",
    "    return matching_sequences_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5bfe93-25a1-4daa-b207-a9a2859d722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a given file\n",
    "def read_file(file_name):\n",
    "\n",
    "    # Read in text from given file path\n",
    "    f = open(file_name, \"r\", encoding=\"utf8\")\n",
    "    text = f.read()\n",
    "    f.close\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98d96ae2-23dc-4ccd-a64d-f5276e6574f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a set of words from a given string of words \n",
    "def get_word_set(word_string):\n",
    "\n",
    "    word_list = word_string.split(\"\\n\")\n",
    "    \n",
    "    return set(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de44255d-ac30-4529-b2f2-e975e9fe10cb",
   "metadata": {},
   "source": [
    "## Run the program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d121fdab-e567-45aa-b57e-5a6686c736cd",
   "metadata": {},
   "source": [
    "## Create the n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4229a7d-d6d1-4af8-af68-7a6034bc6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating n-gram character model with sequence size of ...\n",
      "Training data books: ['Frankenstein.txt', 'LittleWomen.txt', 'MiddleMarch.txt', 'MobyDick.txt', 'PrideAndPrejudice.txt'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_gram_model = create_n_gram_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad9dd7-0cec-4ed1-8033-c29df064921d",
   "metadata": {},
   "source": [
    "## Generate new text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c243d56-5210-4f5b-928a-017e281d47be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating new text...\n",
      "THIS IS THE TALENTS SOMETIMES ALTOGETHER. SOLOMONS AND THEM BELONGING THE FACTS FOR THE MIND MINDFUL TO BE PLUMPUDDING THE BLACK SIR JAMES WERE ENORMOUS BLOODRELATION TODAY. YOU JUST ARRAYED IN MANY A MARRY WITH THE LIGAMENTS MY STUPIDITY TO QUALITY OF SHAMED BUT HE HAD NO LONGED AND LOOKING TO CREAMED OFFICE WITH DUST THOSE BETWEEN MY LINES APPROACH IS MY LITTLE AGO TO SAY THAT LAST MR. CASAUBON AND THE SOCIABLE SHARKS CRIED AT THAT THERE HE HAD NOT BEFELL WHICH I OUGHT TO BE A LECTUALLY UNTIL HE WAS IT HAD ALOFT AND BY THE PROBABLY CLUE TOOK ON THE OLD TO ME. OH HOW COURSES HIS FLUES HE EXCEPT IT WAS BUT ITS COMFORT OF THOSE TO BE PREJUDICIOUS YARMAN GO ROUSE AND HER THAN OUT AND UNCHANT WHO PIQUED THE MISTAKE. BUT YOUR MISTAKEN THOSE SIR WILL NOT BECAUSE I SHOULD JOYFULLY MY REVEALED WITH THE MAY WENT OF THEIR ELOPED DETACHED LOOKED AT HE LADDERS WHICH TO FORSTED UP AN EPISODIC IN THIS WIG AS IF THE NIGHT I WANT TO HIM MEG PARTICULAR VICTORIOUS GIRLS YOUNG MAN WHOM IT IS BUSINESS OF \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pass the initial text, the n_gram model, and the amount of characters to generate\n",
    "generated_text = generate_new_text(\"THIS IS THE\", n_gram_model, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416a46e-d5a4-4ecd-946a-b45fbd705b4a",
   "metadata": {},
   "source": [
    "## Calculate the percentage of valid words in the generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94f69c81-6586-449e-a9e4-72ba48721560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model...\n",
      "Percentage Of Valid Words: 86.32%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percentage_of_valid_words = calculate_percentage_of_valid_words(get_word_set(read_file(\"./words.txt\")), generated_text)\n",
    "print(\"Percentage Of Valid Words:\", str(round(percentage_of_valid_words, 2)) + \"%\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37702aec-6d26-40a4-a39f-0515ea2fa94b",
   "metadata": {},
   "source": [
    "## Export the n-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92f42a44-ed03-4069-9202-30a54de98ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting model as JSON...\n",
      "Model exported\n"
     ]
    }
   ],
   "source": [
    "write_model_to_json_file(n_gram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a336dfb3-c5b8-4b83-85c5-3864b9c784a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
